# PERIHELION-CRAB (GEMINI CONTEXT)

## ğŸ“Œ Project Overview
**Perihelion-Crab** is a data science platform for horse racing analysis (Data Sports Lab). It focuses on Chilean racetracks (HCH, CHS, VSC) and features a hybrid scraping system (Web + PDF) to feed a predictive model.

**Tech Stack:**
- **Backend:** Python 3.10+, Flask 3.0, SQLAlchemy.
- **Database:** SQLite (`data/database.db`).
- **Scraping:**
  - **Web:** Playwright + Requests (`elturf.com`). New `ResultsDetailScraper` for deep results extraction.
  - **PDF:** PyMuPDF (Header Scan) + LlamaExtract (Deep Extraction).
- **Frontend:** HTML5/CSS3 (Vanilla), Glassmorphism UI.

## ğŸ“‚ Key Directory Structure
```
D:/Proyectos/perihelion-crab/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”‚   â”œâ”€â”€ web_scraper.py         # Main entry, calls ResultsDetailScraper
â”‚   â”‚   â”‚   â”œâ”€â”€ results_detail_scraper.py # Dropdown navigation & 12-col heuristic extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_scraper.py         # LlamaIndex logic for PDF processing
â”‚   â”‚   â”‚   â””â”€â”€ utils.py               # Status check logic (P/R/V)
â”‚   â”œâ”€â”€ models.py                # SQLAlchemy DB Models
â”‚   â”œâ”€â”€ routes/                  # Flask Blueprints
â”‚   â””â”€â”€ templates/               # HTML Templates (Batch Scraping UI)
â”œâ”€â”€ data/                        # Data Storage
â”‚   â”œâ”€â”€ web_scraping/            
â”‚   â”‚   â””â”€â”€ resultados_detalle/  # Detailed results JSONs (Source for 'R')
â”‚   â””â”€â”€ pdf_scraping/            # PDFs and extracted JSONs
â”œâ”€â”€ config/                      # Configuration files (menu_config.json)
â”œâ”€â”€ run.py                       # Application Entry Point
â””â”€â”€ requirements.txt             # Project Dependencies
```

## ğŸš€ Running the Project
1. **Activate Virtual Environment:**
   `venv/Scripts/activate`
2. **Run Server:**
   `python run.py`
   - Access at: `http://localhost:8080`

## ğŸ§  Core Concepts

### 1. Scraping Status (P/R/V)
The system tracks the state of each race meeting using three indicators:
- **P (Programas):** Datos de la reuniÃ³n.
- **R (Resultados):** Valida **Resultados Detallados** en `data/web_scraping/resultados_detalle/`. Los resultados simples heredados son ignorados.
- **V (Volantes):** ExtracciÃ³n de PDF mediante IA (LlamaExtract).

### 2. Data Flow
1. **Scrape:**
   - **Results:** `ResultsDetailScraper` usa navegaciÃ³n por dropdown para robustez y un sistema de **heurÃ­stica de contenido** para estandarizar 12 columnas (manejando las 20 de HCH).
   - **Batching:** La UI envÃ­a peticiones secuenciales para procesar mÃºltiples eventos filtrados automÃ¡ticamente.
2. **Ingest:** Data is processed and loaded into SQLite via `app/models.py`.
3. **Analyze:** Historical data is used to train models.

### 3. PDF Processing Strategy
- **Scan:** `fitz` (PyMuPDF) quickly reads the header for Date/Meeting#.
- **Extract:** If date matches, `LlamaExtract` envÃ­a el PDF a LlamaCloud.
- **Fallback:** Regex fallback available.

## âš ï¸ Critical Constraints & Agents Protocol
- **Tools:** Use `mcp-exec` with `rust-mcp-filesystem` tools.
- **Conventions:** Follow `AGENTS.md` protocols.
- **Testing:** Run `python -m pytest tests/` before major PRs.
- **Logs:** Check `logs/app.log` for scraping errors (especialmente warnings de "No se encontrÃ³ la tabla").
